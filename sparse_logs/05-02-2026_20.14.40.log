2026-02-05 20:14:40.792 | INFO     | llmcompressor.metrics.logger:_create_default_logger:357 - Logging all LLM Compressor modifier-level logs to sparse_logs/05-02-2026_20.14.40.log
2026-02-05 20:14:40.792 | DEBUG    | llmcompressor.core.lifecycle:initialize:92 - Initializing compression lifecycle
2026-02-05 20:14:40.792 | INFO     | llmcompressor.recipe.recipe:from_modifiers:68 - Creating recipe from modifiers
2026-02-05 20:14:40.810 | DEBUG    | llmcompressor.core.lifecycle:initialize:105 - Initialized modifier: config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=False ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2026-02-05 20:14:40.810 | INFO     | llmcompressor.core.lifecycle:initialize:110 - Compression lifecycle initialized for 1 modifiers
2026-02-05 20:14:40.810 | INFO     | llmcompressor.pipelines.independent.pipeline:IndependentPipeline:43 - Inferred `SequentialPipeline` for `GPTQModifier`
2026-02-05 20:14:42.217 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:267 - ---- Autowrapper ----
2026-02-05 20:14:42.217 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:268 - @torch.fx.wrap
def wrapped_0(input_ids, inputs_embeds):
    if (input_ids is None) ^ (inputs_embeds is not None):
        raise ValueError('You must specify exactly one of input_ids or inputs_embeds')
    return ()
2026-02-05 20:14:42.217 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:269 - ---------------------
2026-02-05 20:14:42.217 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:267 - ---- Autowrapper ----
2026-02-05 20:14:42.217 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:268 - @torch.fx.wrap
def wrapped_1(input_ids, inputs_embeds):
    if inputs_embeds is None:
        inputs_embeds = self.embed_tokens(input_ids)
    return (inputs_embeds,)
2026-02-05 20:14:42.217 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:269 - ---------------------
2026-02-05 20:14:42.217 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:267 - ---- Autowrapper ----
2026-02-05 20:14:42.217 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:268 - @torch.fx.wrap
def wrapped_2(past_key_values, use_cache):
    if use_cache and past_key_values is None:
        past_key_values = DynamicCache()
    return (past_key_values,)
2026-02-05 20:14:42.217 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:269 - ---------------------
2026-02-05 20:14:42.218 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:267 - ---- Autowrapper ----
2026-02-05 20:14:42.218 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:268 - @torch.fx.wrap
def wrapped_3(cache_position, inputs_embeds, past_key_values, *, past_seen_tokens=None):
    if cache_position is None:
        past_seen_tokens = past_key_values.get_seq_length() if past_key_values is not None else 0
        cache_position = torch.arange(past_seen_tokens, past_seen_tokens + inputs_embeds.shape[1], device=inputs_embeds.device)
    return (cache_position, past_seen_tokens)
2026-02-05 20:14:42.218 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:269 - ---------------------
2026-02-05 20:14:42.218 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:267 - ---- Autowrapper ----
2026-02-05 20:14:42.218 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:268 - @torch.fx.wrap
def wrapped_4(cache_position, position_ids):
    if position_ids is None:
        position_ids = cache_position.unsqueeze(0)
    return (position_ids,)
2026-02-05 20:14:42.218 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:269 - ---------------------
2026-02-05 20:14:42.218 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:267 - ---- Autowrapper ----
2026-02-05 20:14:42.218 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:268 - @torch.fx.wrap
def wrapped_5(attention_mask, cache_position, inputs_embeds, past_key_values, position_ids, *, causal_mask_mapping=None, mask_kwargs=None):
    if not isinstance((causal_mask_mapping := attention_mask), dict):
        mask_kwargs = {'config': self.config, 'input_embeds': inputs_embeds, 'attention_mask': attention_mask, 'cache_position': cache_position, 'past_key_values': past_key_values, 'position_ids': position_ids}
        causal_mask_mapping = {'full_attention': create_causal_mask(**mask_kwargs)}
        if 'sliding_attention' in self.config.layer_types:
            causal_mask_mapping['sliding_attention'] = create_sliding_window_causal_mask(**mask_kwargs)
    return (causal_mask_mapping, mask_kwargs)
2026-02-05 20:14:42.218 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:269 - ---------------------
2026-02-05 20:14:42.220 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:267 - ---- Autowrapper ----
2026-02-05 20:14:42.220 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:268 - @torch.fx.wrap
def wrapped_0(kwargs, labels, logits, loss):
    if labels is not None:
        loss = self.loss_function(logits=logits, labels=labels, vocab_size=self.config.vocab_size, **kwargs)
    return (loss,)
2026-02-05 20:14:42.220 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:269 - ---------------------
2026-02-05 20:14:42.263 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.CALIBRATION_EPOCH_START
2026-02-05 20:14:42.270 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8344597790>
2026-02-05 20:14:42.270 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8344597820>
2026-02-05 20:14:42.270 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83445978e0>
2026-02-05 20:14:42.270 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83445979a0>
2026-02-05 20:14:42.270 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8344597a90>
2026-02-05 20:14:42.270 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8344597b20>
2026-02-05 20:14:42.270 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8344597be0>
2026-02-05 20:14:42.270 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8344597cd0>
2026-02-05 20:14:42.270 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8344597d60>
2026-02-05 20:14:42.270 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8344597e20>
2026-02-05 20:14:42.270 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8344597fa0>
2026-02-05 20:14:42.270 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8344597eb0>
2026-02-05 20:14:42.270 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83445974f0>
2026-02-05 20:14:42.270 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8344597430>
2026-02-05 20:14:42.270 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8344597340>
2026-02-05 20:14:42.270 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83445972b0>
2026-02-05 20:14:42.270 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83445971f0>
2026-02-05 20:14:42.270 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8344597130>
2026-02-05 20:14:42.270 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8344597040>
2026-02-05 20:14:42.270 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8344596fb0>
2026-02-05 20:14:42.270 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8344596ef0>
2026-02-05 20:14:42.271 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8344596e00>
2026-02-05 20:14:42.271 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8344596d70>
2026-02-05 20:14:42.271 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8344596cb0>
2026-02-05 20:14:42.271 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8344596bf0>
2026-02-05 20:14:42.271 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8344596b00>
2026-02-05 20:14:42.271 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8344596a70>
2026-02-05 20:14:42.271 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83445969b0>
2026-02-05 20:14:42.271 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83445968c0>
2026-02-05 20:14:42.271 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8344596830>
2026-02-05 20:14:42.271 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8344596770>
2026-02-05 20:14:42.271 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83445966b0>
2026-02-05 20:14:42.271 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83445965c0>
2026-02-05 20:14:42.271 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8344596530>
2026-02-05 20:14:42.271 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8344596470>
2026-02-05 20:14:42.271 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8344596380>
2026-02-05 20:14:42.271 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83445962f0>
2026-02-05 20:14:42.271 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8344596230>
2026-02-05 20:14:42.271 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8344596170>
2026-02-05 20:14:42.271 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8344596080>
2026-02-05 20:14:42.271 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8344595ff0>
2026-02-05 20:14:42.271 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8344595f30>
2026-02-05 20:14:42.271 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8344595e40>
2026-02-05 20:14:42.271 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8344595db0>
2026-02-05 20:14:42.271 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8344595870>
2026-02-05 20:14:42.271 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83445957b0>
2026-02-05 20:14:42.271 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83445956c0>
2026-02-05 20:14:42.271 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8344595630>
2026-02-05 20:14:42.271 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8344595570>
2026-02-05 20:14:42.271 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8344595480>
2026-02-05 20:14:42.271 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83445953f0>
2026-02-05 20:14:42.271 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8344595330>
2026-02-05 20:14:42.272 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8344595270>
2026-02-05 20:14:42.272 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8344595180>
2026-02-05 20:14:42.272 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83445950f0>
2026-02-05 20:14:42.272 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8344595030>
2026-02-05 20:14:42.272 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8344594f40>
2026-02-05 20:14:42.272 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8344594eb0>
2026-02-05 20:14:42.272 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8344594df0>
2026-02-05 20:14:42.272 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8344594d30>
2026-02-05 20:14:42.272 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83445949d0>
2026-02-05 20:14:42.272 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8344594940>
2026-02-05 20:14:42.272 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8344594880>
2026-02-05 20:14:42.272 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8344594790>
2026-02-05 20:14:42.272 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8344594700>
2026-02-05 20:14:42.272 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8344594640>
2026-02-05 20:14:42.272 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8344594580>
2026-02-05 20:14:42.272 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8344594490>
2026-02-05 20:14:42.272 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8344594310>
2026-02-05 20:14:42.272 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83445941f0>
2026-02-05 20:14:42.272 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8344594190>
2026-02-05 20:14:42.272 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c834454ad40>
2026-02-05 20:14:42.272 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c834454abf0>
2026-02-05 20:14:42.272 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8344549060>
2026-02-05 20:14:42.272 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8344549330>
2026-02-05 20:14:42.272 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8344549450>
2026-02-05 20:14:42.272 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83445495d0>
2026-02-05 20:14:42.272 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83445497b0>
2026-02-05 20:14:42.272 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83445498d0>
2026-02-05 20:14:42.272 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8344549a50>
2026-02-05 20:14:42.272 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8344549bd0>
2026-02-05 20:14:42.272 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8344549db0>
2026-02-05 20:14:42.272 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8344549ed0>
2026-02-05 20:14:42.272 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c834454a050>
2026-02-05 20:14:42.273 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c834454a230>
2026-02-05 20:14:42.273 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c834454a350>
2026-02-05 20:14:42.273 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c834454a4d0>
2026-02-05 20:14:42.273 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c834454aec0>
2026-02-05 20:14:42.273 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c834454aa40>
2026-02-05 20:14:42.273 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c834454add0>
2026-02-05 20:14:42.273 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c834454a530>
2026-02-05 20:14:42.273 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c834454ab30>
2026-02-05 20:14:42.273 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83e23eb880>
2026-02-05 20:14:42.273 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83e23e9330>
2026-02-05 20:14:42.273 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83e23ebac0>
2026-02-05 20:14:42.273 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83e23eb9d0>
2026-02-05 20:14:42.273 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83e23eb910>
2026-02-05 20:14:42.273 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83e23e8bb0>
2026-02-05 20:14:42.273 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83e23eba30>
2026-02-05 20:14:42.273 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83e23e94e0>
2026-02-05 20:14:42.273 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83e23e9db0>
2026-02-05 20:14:42.273 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83e23e9c60>
2026-02-05 20:14:42.273 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83e23e9b70>
2026-02-05 20:14:42.273 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83e23e9d20>
2026-02-05 20:14:42.273 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83e23e9de0>
2026-02-05 20:14:42.273 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83e23e8730>
2026-02-05 20:14:42.273 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83e23e8700>
2026-02-05 20:14:42.273 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83e23ebfd0>
2026-02-05 20:14:42.273 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83e23ea8f0>
2026-02-05 20:14:42.273 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83e23ea710>
2026-02-05 20:14:42.273 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83e23ea680>
2026-02-05 20:14:42.273 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83e23ea5c0>
2026-02-05 20:14:42.273 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83e23ea4d0>
2026-02-05 20:14:42.273 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83e23ea440>
2026-02-05 20:14:42.273 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83e23ea830>
2026-02-05 20:14:42.274 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83e23ea410>
2026-02-05 20:14:42.274 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83e23ea1d0>
2026-02-05 20:14:42.274 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83e23ea200>
2026-02-05 20:14:42.274 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83e23ea2c0>
2026-02-05 20:14:42.274 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83e23e9fc0>
2026-02-05 20:14:42.274 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83e23e9f30>
2026-02-05 20:14:42.274 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83e23ea0e0>
2026-02-05 20:14:42.274 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83e23e97e0>
2026-02-05 20:14:42.274 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83e23e9600>
2026-02-05 20:14:42.274 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83e23e96f0>
2026-02-05 20:14:42.274 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83e23e97b0>
2026-02-05 20:14:42.274 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83e23e9ab0>
2026-02-05 20:14:42.274 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83e23e99f0>
2026-02-05 20:14:42.274 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83e23e9930>
2026-02-05 20:14:42.274 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83e23e93f0>
2026-02-05 20:14:42.274 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83e23ebf70>
2026-02-05 20:14:42.274 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83e23eaa40>
2026-02-05 20:14:42.274 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83e23ea980>
2026-02-05 20:14:42.274 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83e23eaad0>
2026-02-05 20:14:42.274 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83e23ebf10>
2026-02-05 20:14:42.274 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83e23ebeb0>
2026-02-05 20:14:42.274 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83e23ebd60>
2026-02-05 20:14:42.274 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83e23ebc70>
2026-02-05 20:14:42.274 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83e23ebc10>
2026-02-05 20:14:42.274 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83e23eb010>
2026-02-05 20:14:42.274 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83e23eaf20>
2026-02-05 20:14:42.274 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83e23eaef0>
2026-02-05 20:14:42.274 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83e23eae00>
2026-02-05 20:14:42.274 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83e23eace0>
2026-02-05 20:14:42.274 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83e23eabf0>
2026-02-05 20:14:42.274 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83e23eac50>
2026-02-05 20:14:42.274 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83e23e8760>
2026-02-05 20:14:42.274 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83e23e9270>
2026-02-05 20:14:42.275 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8347770040>
2026-02-05 20:14:42.275 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8347770100>
2026-02-05 20:14:42.275 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83477701c0>
2026-02-05 20:14:42.275 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83477702b0>
2026-02-05 20:14:42.275 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8347770340>
2026-02-05 20:14:42.275 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8347770400>
2026-02-05 20:14:42.275 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83477704f0>
2026-02-05 20:14:42.275 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8347770580>
2026-02-05 20:14:42.275 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8347770640>
2026-02-05 20:14:42.275 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8347770700>
2026-02-05 20:14:42.275 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83477707f0>
2026-02-05 20:14:42.275 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8347770880>
2026-02-05 20:14:42.275 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8347770940>
2026-02-05 20:14:42.275 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8347770a30>
2026-02-05 20:14:42.275 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8347770ac0>
2026-02-05 20:14:42.275 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8347770b80>
2026-02-05 20:14:42.275 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8347770c40>
2026-02-05 20:14:42.275 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8347770d30>
2026-02-05 20:14:42.275 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8347770dc0>
2026-02-05 20:14:42.275 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8347770e80>
2026-02-05 20:14:42.275 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8347770f70>
2026-02-05 20:14:42.275 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8347771000>
2026-02-05 20:14:42.275 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83477710c0>
2026-02-05 20:14:42.275 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8347771180>
2026-02-05 20:14:42.275 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8347771270>
2026-02-05 20:14:42.275 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8347771300>
2026-02-05 20:14:42.275 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83477713c0>
2026-02-05 20:14:42.275 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83477714b0>
2026-02-05 20:14:42.275 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8347771540>
2026-02-05 20:14:42.275 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8347771600>
2026-02-05 20:14:42.275 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83477716c0>
2026-02-05 20:14:42.276 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83477717b0>
2026-02-05 20:14:42.276 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8347771840>
2026-02-05 20:14:42.276 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8347771900>
2026-02-05 20:14:42.276 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83477719f0>
2026-02-05 20:14:42.276 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8347771a80>
2026-02-05 20:14:42.276 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8347771b40>
2026-02-05 20:14:42.276 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8347771c00>
2026-02-05 20:14:42.276 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8347771cf0>
2026-02-05 20:14:42.276 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8347771d80>
2026-02-05 20:14:42.276 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8347771e40>
2026-02-05 20:14:42.276 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8347771f30>
2026-02-05 20:14:42.276 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8347771fc0>
2026-02-05 20:14:42.276 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8347772080>
2026-02-05 20:14:42.276 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8347772140>
2026-02-05 20:14:42.276 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8347772230>
2026-02-05 20:14:42.276 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83477722c0>
2026-02-05 20:14:42.276 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8347772380>
2026-02-05 20:14:42.276 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8347772470>
2026-02-05 20:14:42.276 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8347772500>
2026-02-05 20:14:42.276 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83477725c0>
2026-02-05 20:14:42.276 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8347772680>
2026-02-05 20:14:42.276 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8347772770>
2026-02-05 20:14:42.276 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8347772800>
2026-02-05 20:14:42.276 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83477728c0>
2026-02-05 20:14:42.276 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c83477729b0>
2026-02-05 20:14:42.276 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8347772a40>
2026-02-05 20:14:42.276 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8347772b00>
2026-02-05 20:14:42.276 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8347772bc0>
2026-02-05 20:14:42.276 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8347772cb0>
2026-02-05 20:14:42.276 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8347772d40>
2026-02-05 20:14:42.276 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7c8347772e00>
2026-02-05 20:14:42.276 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2026-02-05 20:14:44.511 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-02-05 20:14:44.511 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.0.self_attn.q_proj using 256 samples
2026-02-05 20:14:45.012 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.50s
2026-02-05 20:14:45.013 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1.11
2026-02-05 20:14:45.013 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 9.26% | total memory: 17 GB
2026-02-05 20:14:45.013 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2026-02-05 20:14:45.013 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.0.self_attn.k_proj using 256 samples
2026-02-05 20:14:45.359 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.35s
2026-02-05 20:14:45.359 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 0.33
2026-02-05 20:14:45.360 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 9.26% | total memory: 17 GB
2026-02-05 20:14:45.360 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 2.121728 MB
2026-02-05 20:14:45.360 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.0.self_attn.v_proj using 256 samples
2026-02-05 20:14:45.705 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.35s
2026-02-05 20:14:45.705 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 0.19
2026-02-05 20:14:45.706 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 9.26% | total memory: 17 GB
2026-02-05 20:14:45.706 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 2.121728 MB
2026-02-05 20:14:45.706 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.0.self_attn.o_proj using 256 samples
2026-02-05 20:14:46.059 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.35s
2026-02-05 20:14:46.059 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 0.04
2026-02-05 20:14:46.059 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 9.26% | total memory: 17 GB
2026-02-05 20:14:46.059 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2026-02-05 20:14:46.059 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.0.mlp.gate_proj using 256 samples
2026-02-05 20:14:46.433 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.37s
2026-02-05 20:14:46.433 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 4.42
2026-02-05 20:14:46.434 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 9.26% | total memory: 17 GB
2026-02-05 20:14:46.434 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:14:46.434 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.0.mlp.up_proj using 256 samples
2026-02-05 20:14:46.803 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.37s
2026-02-05 20:14:46.803 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 3.42
2026-02-05 20:14:46.804 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 9.26% | total memory: 17 GB
2026-02-05 20:14:46.804 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:14:46.804 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.0.mlp.down_proj using 256 samples
2026-02-05 20:14:47.540 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.74s
2026-02-05 20:14:47.540 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 0.00
2026-02-05 20:14:47.540 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 9.66% | total memory: 17 GB
2026-02-05 20:14:47.540 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:14:47.540 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2026-02-05 20:14:49.981 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-02-05 20:14:49.981 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.1.self_attn.q_proj using 256 samples
2026-02-05 20:14:50.340 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.36s
2026-02-05 20:14:50.340 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 4.76
2026-02-05 20:14:50.340 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:14:50.340 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2026-02-05 20:14:50.340 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.1.self_attn.k_proj using 256 samples
2026-02-05 20:14:50.684 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.34s
2026-02-05 20:14:50.684 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1.36
2026-02-05 20:14:50.684 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:14:50.684 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 2.121728 MB
2026-02-05 20:14:50.685 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.1.self_attn.v_proj using 256 samples
2026-02-05 20:14:51.029 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.34s
2026-02-05 20:14:51.029 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1.27
2026-02-05 20:14:51.030 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:14:51.030 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 2.121728 MB
2026-02-05 20:14:51.030 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.1.self_attn.o_proj using 256 samples
2026-02-05 20:14:51.379 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.35s
2026-02-05 20:14:51.379 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 0.21
2026-02-05 20:14:51.379 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:14:51.379 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2026-02-05 20:14:51.379 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.1.mlp.gate_proj using 256 samples
2026-02-05 20:14:51.770 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.39s
2026-02-05 20:14:51.770 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 17.35
2026-02-05 20:14:51.770 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:14:51.770 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:14:51.771 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.1.mlp.up_proj using 256 samples
2026-02-05 20:14:52.141 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.37s
2026-02-05 20:14:52.141 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 15.74
2026-02-05 20:14:52.141 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:14:52.142 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:14:52.142 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.1.mlp.down_proj using 256 samples
2026-02-05 20:14:52.875 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.73s
2026-02-05 20:14:52.875 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 0.01
2026-02-05 20:14:52.876 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.20% | total memory: 17 GB
2026-02-05 20:14:52.876 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:14:52.876 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2026-02-05 20:14:54.961 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-02-05 20:14:54.961 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.2.self_attn.q_proj using 256 samples
2026-02-05 20:14:55.323 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.36s
2026-02-05 20:14:55.323 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 12.95
2026-02-05 20:14:55.323 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:14:55.323 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2026-02-05 20:14:55.323 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.2.self_attn.k_proj using 256 samples
2026-02-05 20:14:55.669 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.35s
2026-02-05 20:14:55.669 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 3.64
2026-02-05 20:14:55.669 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:14:55.669 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 2.121728 MB
2026-02-05 20:14:55.669 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.2.self_attn.v_proj using 256 samples
2026-02-05 20:14:56.016 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.35s
2026-02-05 20:14:56.016 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 3.57
2026-02-05 20:14:56.017 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:14:56.017 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 2.121728 MB
2026-02-05 20:14:56.017 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.2.self_attn.o_proj using 256 samples
2026-02-05 20:14:56.369 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.35s
2026-02-05 20:14:56.370 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 0.57
2026-02-05 20:14:56.370 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:14:56.370 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2026-02-05 20:14:56.370 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.2.mlp.gate_proj using 256 samples
2026-02-05 20:14:56.743 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.37s
2026-02-05 20:14:56.743 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 41.27
2026-02-05 20:14:56.743 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:14:56.743 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:14:56.743 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.2.mlp.up_proj using 256 samples
2026-02-05 20:14:57.115 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.37s
2026-02-05 20:14:57.115 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 36.96
2026-02-05 20:14:57.115 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:14:57.115 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:14:57.116 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.2.mlp.down_proj using 256 samples
2026-02-05 20:14:57.849 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.73s
2026-02-05 20:14:57.849 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 0.04
2026-02-05 20:14:57.849 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.20% | total memory: 17 GB
2026-02-05 20:14:57.849 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:14:57.849 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2026-02-05 20:14:59.817 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-02-05 20:14:59.817 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.3.self_attn.q_proj using 256 samples
2026-02-05 20:15:00.174 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.36s
2026-02-05 20:15:00.174 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 26.44
2026-02-05 20:15:00.174 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:15:00.175 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2026-02-05 20:15:00.175 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.3.self_attn.k_proj using 256 samples
2026-02-05 20:15:00.520 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.35s
2026-02-05 20:15:00.520 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 7.46
2026-02-05 20:15:00.521 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:15:00.521 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 2.121728 MB
2026-02-05 20:15:00.521 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.3.self_attn.v_proj using 256 samples
2026-02-05 20:15:00.865 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.34s
2026-02-05 20:15:00.865 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 6.71
2026-02-05 20:15:00.865 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:15:00.865 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 2.121728 MB
2026-02-05 20:15:00.865 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.3.self_attn.o_proj using 256 samples
2026-02-05 20:15:01.217 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.35s
2026-02-05 20:15:01.220 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 0.48
2026-02-05 20:15:01.221 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:15:01.221 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2026-02-05 20:15:01.221 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.3.mlp.gate_proj using 256 samples
2026-02-05 20:15:01.590 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.37s
2026-02-05 20:15:01.590 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 77.86
2026-02-05 20:15:01.590 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:15:01.590 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:15:01.591 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.3.mlp.up_proj using 256 samples
2026-02-05 20:15:01.978 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.39s
2026-02-05 20:15:01.978 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 67.81
2026-02-05 20:15:01.978 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:15:01.979 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:15:01.979 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.3.mlp.down_proj using 256 samples
2026-02-05 20:15:02.719 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.74s
2026-02-05 20:15:02.719 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 0.12
2026-02-05 20:15:02.719 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.20% | total memory: 17 GB
2026-02-05 20:15:02.719 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:15:02.719 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2026-02-05 20:15:04.689 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-02-05 20:15:04.690 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.4.self_attn.q_proj using 256 samples
2026-02-05 20:15:05.048 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.36s
2026-02-05 20:15:05.048 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 50.28
2026-02-05 20:15:05.048 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:15:05.048 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2026-02-05 20:15:05.048 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.4.self_attn.k_proj using 256 samples
2026-02-05 20:15:05.393 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.34s
2026-02-05 20:15:05.393 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 13.94
2026-02-05 20:15:05.393 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:15:05.393 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 2.121728 MB
2026-02-05 20:15:05.394 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.4.self_attn.v_proj using 256 samples
2026-02-05 20:15:05.740 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.35s
2026-02-05 20:15:05.740 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 12.76
2026-02-05 20:15:05.741 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:15:05.741 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 2.121728 MB
2026-02-05 20:15:05.741 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.4.self_attn.o_proj using 256 samples
2026-02-05 20:15:06.093 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.35s
2026-02-05 20:15:06.093 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1.30
2026-02-05 20:15:06.093 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:15:06.093 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2026-02-05 20:15:06.093 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.4.mlp.gate_proj using 256 samples
2026-02-05 20:15:06.466 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.37s
2026-02-05 20:15:06.469 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 147.13
2026-02-05 20:15:06.469 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:15:06.469 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:15:06.469 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.4.mlp.up_proj using 256 samples
2026-02-05 20:15:06.840 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.37s
2026-02-05 20:15:06.840 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 126.60
2026-02-05 20:15:06.840 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:15:06.840 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:15:06.840 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.4.mlp.down_proj using 256 samples
2026-02-05 20:15:07.578 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.74s
2026-02-05 20:15:07.578 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 0.30
2026-02-05 20:15:07.579 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.20% | total memory: 17 GB
2026-02-05 20:15:07.579 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:15:07.579 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2026-02-05 20:15:09.546 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-02-05 20:15:09.546 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.5.self_attn.q_proj using 256 samples
2026-02-05 20:15:09.904 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.36s
2026-02-05 20:15:09.904 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 81.43
2026-02-05 20:15:09.904 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:15:09.904 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2026-02-05 20:15:09.904 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.5.self_attn.k_proj using 256 samples
2026-02-05 20:15:10.249 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.35s
2026-02-05 20:15:10.250 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 23.92
2026-02-05 20:15:10.250 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:15:10.250 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 2.121728 MB
2026-02-05 20:15:10.250 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.5.self_attn.v_proj using 256 samples
2026-02-05 20:15:10.594 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.34s
2026-02-05 20:15:10.594 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 20.85
2026-02-05 20:15:10.595 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:15:10.595 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 2.121728 MB
2026-02-05 20:15:10.595 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.5.self_attn.o_proj using 256 samples
2026-02-05 20:15:10.946 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.35s
2026-02-05 20:15:10.947 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 2.42
2026-02-05 20:15:10.947 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:15:10.947 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2026-02-05 20:15:10.947 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.5.mlp.gate_proj using 256 samples
2026-02-05 20:15:11.321 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.37s
2026-02-05 20:15:11.321 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 294.74
2026-02-05 20:15:11.322 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:15:11.322 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:15:11.322 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.5.mlp.up_proj using 256 samples
2026-02-05 20:15:11.693 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.37s
2026-02-05 20:15:11.693 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 196.82
2026-02-05 20:15:11.693 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:15:11.693 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:15:11.693 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.5.mlp.down_proj using 256 samples
2026-02-05 20:15:12.447 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.75s
2026-02-05 20:15:12.448 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1.09
2026-02-05 20:15:12.448 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.20% | total memory: 17 GB
2026-02-05 20:15:12.448 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:15:12.448 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2026-02-05 20:15:14.417 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-02-05 20:15:14.417 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.6.self_attn.q_proj using 256 samples
2026-02-05 20:15:14.776 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.36s
2026-02-05 20:15:14.776 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 118.71
2026-02-05 20:15:14.776 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:15:14.776 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2026-02-05 20:15:14.776 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.6.self_attn.k_proj using 256 samples
2026-02-05 20:15:15.127 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.35s
2026-02-05 20:15:15.127 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 32.67
2026-02-05 20:15:15.127 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:15:15.127 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 2.121728 MB
2026-02-05 20:15:15.127 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.6.self_attn.v_proj using 256 samples
2026-02-05 20:15:15.474 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.35s
2026-02-05 20:15:15.474 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 32.55
2026-02-05 20:15:15.474 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:15:15.474 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 2.121728 MB
2026-02-05 20:15:15.475 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.6.self_attn.o_proj using 256 samples
2026-02-05 20:15:15.828 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.35s
2026-02-05 20:15:15.828 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 7.80
2026-02-05 20:15:15.828 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:15:15.828 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2026-02-05 20:15:15.828 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.6.mlp.gate_proj using 256 samples
2026-02-05 20:15:16.201 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.37s
2026-02-05 20:15:16.201 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 437.90
2026-02-05 20:15:16.202 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:15:16.202 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:15:16.202 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.6.mlp.up_proj using 256 samples
2026-02-05 20:15:16.575 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.37s
2026-02-05 20:15:16.576 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 304.40
2026-02-05 20:15:16.576 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:15:16.576 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:15:16.576 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.6.mlp.down_proj using 256 samples
2026-02-05 20:15:17.309 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.73s
2026-02-05 20:15:17.309 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 2.46
2026-02-05 20:15:17.309 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.20% | total memory: 17 GB
2026-02-05 20:15:17.310 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:15:17.310 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2026-02-05 20:15:19.275 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-02-05 20:15:19.275 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.7.self_attn.q_proj using 256 samples
2026-02-05 20:15:19.635 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.36s
2026-02-05 20:15:19.635 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 179.05
2026-02-05 20:15:19.635 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:15:19.635 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2026-02-05 20:15:19.635 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.7.self_attn.k_proj using 256 samples
2026-02-05 20:15:19.982 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.35s
2026-02-05 20:15:19.983 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 50.35
2026-02-05 20:15:19.983 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:15:19.983 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 2.121728 MB
2026-02-05 20:15:19.983 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.7.self_attn.v_proj using 256 samples
2026-02-05 20:15:20.328 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.35s
2026-02-05 20:15:20.328 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 45.64
2026-02-05 20:15:20.329 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:15:20.329 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 2.121728 MB
2026-02-05 20:15:20.329 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.7.self_attn.o_proj using 256 samples
2026-02-05 20:15:20.679 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.35s
2026-02-05 20:15:20.679 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 9.18
2026-02-05 20:15:20.679 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:15:20.679 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2026-02-05 20:15:20.680 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.7.mlp.gate_proj using 256 samples
2026-02-05 20:15:21.054 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.37s
2026-02-05 20:15:21.055 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 680.96
2026-02-05 20:15:21.055 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:15:21.055 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:15:21.055 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.7.mlp.up_proj using 256 samples
2026-02-05 20:15:21.426 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.37s
2026-02-05 20:15:21.426 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 433.55
2026-02-05 20:15:21.427 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:15:21.427 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:15:21.427 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.7.mlp.down_proj using 256 samples
2026-02-05 20:15:22.162 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.74s
2026-02-05 20:15:22.162 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 5.11
2026-02-05 20:15:22.163 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.20% | total memory: 17 GB
2026-02-05 20:15:22.163 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:15:22.163 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2026-02-05 20:15:24.137 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-02-05 20:15:24.137 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.8.self_attn.q_proj using 256 samples
2026-02-05 20:15:24.494 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.36s
2026-02-05 20:15:24.495 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 195.55
2026-02-05 20:15:24.495 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:15:24.495 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2026-02-05 20:15:24.495 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.8.self_attn.k_proj using 256 samples
2026-02-05 20:15:24.842 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.35s
2026-02-05 20:15:24.842 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 55.81
2026-02-05 20:15:24.842 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:15:24.842 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 2.121728 MB
2026-02-05 20:15:24.842 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.8.self_attn.v_proj using 256 samples
2026-02-05 20:15:25.187 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.34s
2026-02-05 20:15:25.188 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 55.71
2026-02-05 20:15:25.188 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:15:25.188 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 2.121728 MB
2026-02-05 20:15:25.188 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.8.self_attn.o_proj using 256 samples
2026-02-05 20:15:25.539 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.35s
2026-02-05 20:15:25.539 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 9.81
2026-02-05 20:15:25.539 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:15:25.539 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2026-02-05 20:15:25.539 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.8.mlp.gate_proj using 256 samples
2026-02-05 20:15:25.909 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.37s
2026-02-05 20:15:25.909 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 628.55
2026-02-05 20:15:25.909 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:15:25.909 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:15:25.909 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.8.mlp.up_proj using 256 samples
2026-02-05 20:15:26.278 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.37s
2026-02-05 20:15:26.278 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 484.87
2026-02-05 20:15:26.278 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:15:26.278 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:15:26.278 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.8.mlp.down_proj using 256 samples
2026-02-05 20:15:27.010 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.73s
2026-02-05 20:15:27.010 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 5.66
2026-02-05 20:15:27.010 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.20% | total memory: 17 GB
2026-02-05 20:15:27.011 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:15:27.011 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2026-02-05 20:15:28.981 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-02-05 20:15:28.981 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.9.self_attn.q_proj using 256 samples
2026-02-05 20:15:29.340 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.36s
2026-02-05 20:15:29.340 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 260.62
2026-02-05 20:15:29.341 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:15:29.341 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2026-02-05 20:15:29.341 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.9.self_attn.k_proj using 256 samples
2026-02-05 20:15:29.687 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.35s
2026-02-05 20:15:29.688 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 76.96
2026-02-05 20:15:29.688 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:15:29.688 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 2.121728 MB
2026-02-05 20:15:29.688 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.9.self_attn.v_proj using 256 samples
2026-02-05 20:15:30.035 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.35s
2026-02-05 20:15:30.035 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 75.26
2026-02-05 20:15:30.035 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:15:30.035 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 2.121728 MB
2026-02-05 20:15:30.035 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.9.self_attn.o_proj using 256 samples
2026-02-05 20:15:30.384 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.35s
2026-02-05 20:15:30.384 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 13.54
2026-02-05 20:15:30.385 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:15:30.385 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2026-02-05 20:15:30.385 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.9.mlp.gate_proj using 256 samples
2026-02-05 20:15:30.738 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.35s
2026-02-05 20:15:30.739 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 732.90
2026-02-05 20:15:30.739 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:15:30.739 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:15:30.739 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.9.mlp.up_proj using 256 samples
2026-02-05 20:15:31.092 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.35s
2026-02-05 20:15:31.093 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 602.16
2026-02-05 20:15:31.093 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:15:31.093 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:15:31.093 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.9.mlp.down_proj using 256 samples
2026-02-05 20:15:31.813 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.72s
2026-02-05 20:15:31.814 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 7.72
2026-02-05 20:15:31.814 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.20% | total memory: 17 GB
2026-02-05 20:15:31.814 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:15:31.814 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2026-02-05 20:15:33.786 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-02-05 20:15:33.786 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.10.self_attn.q_proj using 256 samples
2026-02-05 20:15:34.143 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.36s
2026-02-05 20:15:34.143 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 283.16
2026-02-05 20:15:34.143 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:15:34.143 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2026-02-05 20:15:34.143 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.10.self_attn.k_proj using 256 samples
2026-02-05 20:15:34.489 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.35s
2026-02-05 20:15:34.489 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 76.29
2026-02-05 20:15:34.489 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:15:34.489 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 2.121728 MB
2026-02-05 20:15:34.489 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.10.self_attn.v_proj using 256 samples
2026-02-05 20:15:34.835 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.35s
2026-02-05 20:15:34.835 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 81.19
2026-02-05 20:15:34.835 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:15:34.835 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 2.121728 MB
2026-02-05 20:15:34.835 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.10.self_attn.o_proj using 256 samples
2026-02-05 20:15:35.185 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.35s
2026-02-05 20:15:35.185 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 11.74
2026-02-05 20:15:35.185 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:15:35.185 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2026-02-05 20:15:35.185 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.10.mlp.gate_proj using 256 samples
2026-02-05 20:15:35.546 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.36s
2026-02-05 20:15:35.546 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 889.03
2026-02-05 20:15:35.546 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:15:35.546 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:15:35.546 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.10.mlp.up_proj using 256 samples
2026-02-05 20:15:35.906 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.36s
2026-02-05 20:15:35.907 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 671.95
2026-02-05 20:15:35.907 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:15:35.907 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:15:35.907 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.10.mlp.down_proj using 256 samples
2026-02-05 20:15:36.625 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.72s
2026-02-05 20:15:36.626 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 9.15
2026-02-05 20:15:36.626 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.20% | total memory: 17 GB
2026-02-05 20:15:36.626 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:15:36.626 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2026-02-05 20:15:38.596 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-02-05 20:15:38.596 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.11.self_attn.q_proj using 256 samples
2026-02-05 20:15:38.958 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.36s
2026-02-05 20:15:38.958 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 307.54
2026-02-05 20:15:38.958 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:15:38.958 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2026-02-05 20:15:38.958 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.11.self_attn.k_proj using 256 samples
2026-02-05 20:15:39.304 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.35s
2026-02-05 20:15:39.304 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 87.00
2026-02-05 20:15:39.304 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:15:39.304 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 2.121728 MB
2026-02-05 20:15:39.304 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.11.self_attn.v_proj using 256 samples
2026-02-05 20:15:39.650 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.35s
2026-02-05 20:15:39.651 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 92.66
2026-02-05 20:15:39.651 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:15:39.651 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 2.121728 MB
2026-02-05 20:15:39.651 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.11.self_attn.o_proj using 256 samples
2026-02-05 20:15:40.007 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.36s
2026-02-05 20:15:40.007 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 17.73
2026-02-05 20:15:40.007 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:15:40.008 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2026-02-05 20:15:40.008 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.11.mlp.gate_proj using 256 samples
2026-02-05 20:15:40.381 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.37s
2026-02-05 20:15:40.382 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 812.53
2026-02-05 20:15:40.382 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:15:40.382 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:15:40.382 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.11.mlp.up_proj using 256 samples
2026-02-05 20:15:40.753 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.37s
2026-02-05 20:15:40.754 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 716.25
2026-02-05 20:15:40.754 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:15:40.754 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:15:40.754 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.11.mlp.down_proj using 256 samples
2026-02-05 20:15:41.487 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.73s
2026-02-05 20:15:41.487 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 8.45
2026-02-05 20:15:41.487 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.20% | total memory: 17 GB
2026-02-05 20:15:41.487 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:15:41.487 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2026-02-05 20:15:43.461 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-02-05 20:15:43.461 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.12.self_attn.q_proj using 256 samples
2026-02-05 20:15:43.822 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.36s
2026-02-05 20:15:43.822 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 345.13
2026-02-05 20:15:43.822 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:15:43.825 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2026-02-05 20:15:43.825 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.12.self_attn.k_proj using 256 samples
2026-02-05 20:15:44.170 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.34s
2026-02-05 20:15:44.170 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 94.58
2026-02-05 20:15:44.170 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:15:44.170 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 2.121728 MB
2026-02-05 20:15:44.170 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.12.self_attn.v_proj using 256 samples
2026-02-05 20:15:44.515 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.34s
2026-02-05 20:15:44.516 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 99.26
2026-02-05 20:15:44.516 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:15:44.516 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 2.121728 MB
2026-02-05 20:15:44.516 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.12.self_attn.o_proj using 256 samples
2026-02-05 20:15:44.864 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.35s
2026-02-05 20:15:44.864 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 14.50
2026-02-05 20:15:44.865 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:15:44.865 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2026-02-05 20:15:44.865 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.12.mlp.gate_proj using 256 samples
2026-02-05 20:15:45.240 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.38s
2026-02-05 20:15:45.241 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 867.13
2026-02-05 20:15:45.241 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:15:45.241 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:15:45.241 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.12.mlp.up_proj using 256 samples
2026-02-05 20:15:45.614 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.37s
2026-02-05 20:15:45.614 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 806.19
2026-02-05 20:15:45.614 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:15:45.614 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:15:45.614 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.12.mlp.down_proj using 256 samples
2026-02-05 20:15:46.347 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.73s
2026-02-05 20:15:46.347 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 10.96
2026-02-05 20:15:46.348 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.20% | total memory: 17 GB
2026-02-05 20:15:46.348 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:15:46.348 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2026-02-05 20:15:48.320 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-02-05 20:15:48.320 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.13.self_attn.q_proj using 256 samples
2026-02-05 20:15:48.676 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.36s
2026-02-05 20:15:48.676 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 386.80
2026-02-05 20:15:48.676 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:15:48.676 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2026-02-05 20:15:48.676 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.13.self_attn.k_proj using 256 samples
2026-02-05 20:15:49.021 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.34s
2026-02-05 20:15:49.021 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 108.45
2026-02-05 20:15:49.022 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:15:49.022 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 2.121728 MB
2026-02-05 20:15:49.022 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.13.self_attn.v_proj using 256 samples
2026-02-05 20:15:49.365 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.34s
2026-02-05 20:15:49.365 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 148.94
2026-02-05 20:15:49.365 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:15:49.365 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 2.121728 MB
2026-02-05 20:15:49.366 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.13.self_attn.o_proj using 256 samples
2026-02-05 20:15:49.716 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.35s
2026-02-05 20:15:49.716 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 44.28
2026-02-05 20:15:49.716 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:15:49.716 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2026-02-05 20:15:49.717 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.13.mlp.gate_proj using 256 samples
2026-02-05 20:15:50.091 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.37s
2026-02-05 20:15:50.091 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 923.81
2026-02-05 20:15:50.091 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:15:50.091 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:15:50.091 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.13.mlp.up_proj using 256 samples
2026-02-05 20:15:50.469 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.38s
2026-02-05 20:15:50.469 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 876.54
2026-02-05 20:15:50.469 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:15:50.469 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:15:50.469 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.13.mlp.down_proj using 256 samples
2026-02-05 20:15:51.210 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.74s
2026-02-05 20:15:51.211 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 12.84
2026-02-05 20:15:51.211 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.20% | total memory: 17 GB
2026-02-05 20:15:51.211 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:15:51.211 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2026-02-05 20:15:53.192 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-02-05 20:15:53.192 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.14.self_attn.q_proj using 256 samples
2026-02-05 20:15:53.563 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.37s
2026-02-05 20:15:53.563 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 419.54
2026-02-05 20:15:53.563 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:15:53.564 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2026-02-05 20:15:53.564 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.14.self_attn.k_proj using 256 samples
2026-02-05 20:15:53.919 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.36s
2026-02-05 20:15:53.919 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 126.15
2026-02-05 20:15:53.920 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:15:53.920 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 2.121728 MB
2026-02-05 20:15:53.920 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.14.self_attn.v_proj using 256 samples
2026-02-05 20:15:54.269 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.35s
2026-02-05 20:15:54.270 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 119.59
2026-02-05 20:15:54.270 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:15:54.270 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 2.121728 MB
2026-02-05 20:15:54.270 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.14.self_attn.o_proj using 256 samples
2026-02-05 20:15:54.623 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.35s
2026-02-05 20:15:54.623 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 27.65
2026-02-05 20:15:54.623 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:15:54.623 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2026-02-05 20:15:54.623 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.14.mlp.gate_proj using 256 samples
2026-02-05 20:15:54.995 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.37s
2026-02-05 20:15:54.996 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 948.80
2026-02-05 20:15:54.996 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:15:54.996 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:15:54.996 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.14.mlp.up_proj using 256 samples
2026-02-05 20:15:55.369 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.37s
2026-02-05 20:15:55.369 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 960.83
2026-02-05 20:15:55.370 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:15:55.370 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:15:55.370 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.14.mlp.down_proj using 256 samples
2026-02-05 20:15:56.106 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.74s
2026-02-05 20:15:56.107 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 13.44
2026-02-05 20:15:56.107 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.20% | total memory: 17 GB
2026-02-05 20:15:56.107 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:15:56.107 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2026-02-05 20:15:58.082 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-02-05 20:15:58.082 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.15.self_attn.q_proj using 256 samples
2026-02-05 20:15:58.439 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.36s
2026-02-05 20:15:58.439 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 434.84
2026-02-05 20:15:58.439 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:15:58.440 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2026-02-05 20:15:58.440 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.15.self_attn.k_proj using 256 samples
2026-02-05 20:15:58.784 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.34s
2026-02-05 20:15:58.784 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 122.36
2026-02-05 20:15:58.784 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:15:58.784 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 2.121728 MB
2026-02-05 20:15:58.784 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.15.self_attn.v_proj using 256 samples
2026-02-05 20:15:59.130 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.35s
2026-02-05 20:15:59.131 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 123.40
2026-02-05 20:15:59.131 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:15:59.131 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 2.121728 MB
2026-02-05 20:15:59.131 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.15.self_attn.o_proj using 256 samples
2026-02-05 20:15:59.482 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.35s
2026-02-05 20:15:59.482 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 18.70
2026-02-05 20:15:59.483 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:15:59.483 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2026-02-05 20:15:59.483 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.15.mlp.gate_proj using 256 samples
2026-02-05 20:15:59.856 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.37s
2026-02-05 20:15:59.856 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1022.07
2026-02-05 20:15:59.856 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:15:59.857 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:15:59.857 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.15.mlp.up_proj using 256 samples
2026-02-05 20:16:00.230 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.37s
2026-02-05 20:16:00.231 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1060.58
2026-02-05 20:16:00.231 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:16:00.231 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:16:00.231 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.15.mlp.down_proj using 256 samples
2026-02-05 20:16:00.966 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.74s
2026-02-05 20:16:00.967 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 15.10
2026-02-05 20:16:00.967 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.20% | total memory: 17 GB
2026-02-05 20:16:00.967 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:16:00.967 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2026-02-05 20:16:02.948 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-02-05 20:16:02.948 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.16.self_attn.q_proj using 256 samples
2026-02-05 20:16:03.310 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.36s
2026-02-05 20:16:03.311 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 514.24
2026-02-05 20:16:03.311 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:16:03.311 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2026-02-05 20:16:03.311 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.16.self_attn.k_proj using 256 samples
2026-02-05 20:16:03.662 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.35s
2026-02-05 20:16:03.662 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 134.61
2026-02-05 20:16:03.662 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:16:03.662 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 2.121728 MB
2026-02-05 20:16:03.663 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.16.self_attn.v_proj using 256 samples
2026-02-05 20:16:04.031 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.37s
2026-02-05 20:16:04.031 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 136.11
2026-02-05 20:16:04.032 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:16:04.032 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 2.121728 MB
2026-02-05 20:16:04.032 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.16.self_attn.o_proj using 256 samples
2026-02-05 20:16:04.384 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.35s
2026-02-05 20:16:04.384 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 16.71
2026-02-05 20:16:04.384 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:16:04.384 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2026-02-05 20:16:04.384 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.16.mlp.gate_proj using 256 samples
2026-02-05 20:16:04.757 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.37s
2026-02-05 20:16:04.757 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1088.84
2026-02-05 20:16:04.757 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:16:04.757 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:16:04.757 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.16.mlp.up_proj using 256 samples
2026-02-05 20:16:05.129 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.37s
2026-02-05 20:16:05.130 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1172.81
2026-02-05 20:16:05.130 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:16:05.130 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:16:05.130 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.16.mlp.down_proj using 256 samples
2026-02-05 20:16:05.858 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.73s
2026-02-05 20:16:05.859 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 17.65
2026-02-05 20:16:05.859 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.20% | total memory: 17 GB
2026-02-05 20:16:05.859 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:16:05.859 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2026-02-05 20:16:07.835 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-02-05 20:16:07.835 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.17.self_attn.q_proj using 256 samples
2026-02-05 20:16:08.196 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.36s
2026-02-05 20:16:08.197 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 532.74
2026-02-05 20:16:08.197 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:16:08.197 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2026-02-05 20:16:08.197 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.17.self_attn.k_proj using 256 samples
2026-02-05 20:16:08.551 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.35s
2026-02-05 20:16:08.552 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 144.48
2026-02-05 20:16:08.552 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:16:08.552 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 2.121728 MB
2026-02-05 20:16:08.552 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.17.self_attn.v_proj using 256 samples
2026-02-05 20:16:08.899 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.35s
2026-02-05 20:16:08.899 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 164.62
2026-02-05 20:16:08.899 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:16:08.899 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 2.121728 MB
2026-02-05 20:16:08.900 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.17.self_attn.o_proj using 256 samples
2026-02-05 20:16:09.255 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.36s
2026-02-05 20:16:09.255 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 14.15
2026-02-05 20:16:09.255 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:16:09.255 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2026-02-05 20:16:09.255 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.17.mlp.gate_proj using 256 samples
2026-02-05 20:16:09.626 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.37s
2026-02-05 20:16:09.627 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1101.11
2026-02-05 20:16:09.627 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:16:09.627 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:16:09.627 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.17.mlp.up_proj using 256 samples
2026-02-05 20:16:09.997 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.37s
2026-02-05 20:16:09.998 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1213.38
2026-02-05 20:16:09.998 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:16:09.998 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:16:09.998 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.17.mlp.down_proj using 256 samples
2026-02-05 20:16:10.730 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.73s
2026-02-05 20:16:10.730 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 18.08
2026-02-05 20:16:10.731 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.20% | total memory: 17 GB
2026-02-05 20:16:10.731 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:16:10.731 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2026-02-05 20:16:12.704 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-02-05 20:16:12.704 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.18.self_attn.q_proj using 256 samples
2026-02-05 20:16:13.063 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.36s
2026-02-05 20:16:13.063 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 585.81
2026-02-05 20:16:13.063 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:16:13.063 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2026-02-05 20:16:13.063 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.18.self_attn.k_proj using 256 samples
2026-02-05 20:16:13.408 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.34s
2026-02-05 20:16:13.408 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 166.47
2026-02-05 20:16:13.408 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:16:13.408 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 2.121728 MB
2026-02-05 20:16:13.408 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.18.self_attn.v_proj using 256 samples
2026-02-05 20:16:13.755 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.35s
2026-02-05 20:16:13.756 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 165.38
2026-02-05 20:16:13.756 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:16:13.756 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 2.121728 MB
2026-02-05 20:16:13.756 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.18.self_attn.o_proj using 256 samples
2026-02-05 20:16:14.112 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.36s
2026-02-05 20:16:14.112 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 21.06
2026-02-05 20:16:14.113 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:16:14.113 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2026-02-05 20:16:14.113 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.18.mlp.gate_proj using 256 samples
2026-02-05 20:16:14.510 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.40s
2026-02-05 20:16:14.511 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1211.40
2026-02-05 20:16:14.511 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:16:14.511 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:16:14.511 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.18.mlp.up_proj using 256 samples
2026-02-05 20:16:14.884 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.37s
2026-02-05 20:16:14.884 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1376.58
2026-02-05 20:16:14.885 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:16:14.885 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:16:14.885 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.18.mlp.down_proj using 256 samples
2026-02-05 20:16:15.620 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.73s
2026-02-05 20:16:15.620 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 23.84
2026-02-05 20:16:15.620 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.20% | total memory: 17 GB
2026-02-05 20:16:15.620 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:16:15.621 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2026-02-05 20:16:17.589 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-02-05 20:16:17.589 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.19.self_attn.q_proj using 256 samples
2026-02-05 20:16:17.947 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.36s
2026-02-05 20:16:17.947 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 589.87
2026-02-05 20:16:17.948 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:16:17.948 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2026-02-05 20:16:17.948 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.19.self_attn.k_proj using 256 samples
2026-02-05 20:16:18.293 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.35s
2026-02-05 20:16:18.294 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 168.52
2026-02-05 20:16:18.294 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:16:18.294 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 2.121728 MB
2026-02-05 20:16:18.294 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.19.self_attn.v_proj using 256 samples
2026-02-05 20:16:18.639 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.34s
2026-02-05 20:16:18.639 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 185.22
2026-02-05 20:16:18.639 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:16:18.639 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 2.121728 MB
2026-02-05 20:16:18.639 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.19.self_attn.o_proj using 256 samples
2026-02-05 20:16:18.993 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.35s
2026-02-05 20:16:18.993 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 32.49
2026-02-05 20:16:18.994 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:16:18.994 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2026-02-05 20:16:18.994 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.19.mlp.gate_proj using 256 samples
2026-02-05 20:16:19.367 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.37s
2026-02-05 20:16:19.367 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1375.45
2026-02-05 20:16:19.368 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:16:19.368 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:16:19.368 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.19.mlp.up_proj using 256 samples
2026-02-05 20:16:19.739 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.37s
2026-02-05 20:16:19.740 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1522.13
2026-02-05 20:16:19.740 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:16:19.740 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:16:19.740 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.19.mlp.down_proj using 256 samples
2026-02-05 20:16:20.475 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.74s
2026-02-05 20:16:20.476 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 31.95
2026-02-05 20:16:20.476 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.20% | total memory: 17 GB
2026-02-05 20:16:20.476 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:16:20.476 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2026-02-05 20:16:22.444 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-02-05 20:16:22.444 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.20.self_attn.q_proj using 256 samples
2026-02-05 20:16:22.803 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.36s
2026-02-05 20:16:22.803 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 699.92
2026-02-05 20:16:22.803 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:16:22.803 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2026-02-05 20:16:22.804 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.20.self_attn.k_proj using 256 samples
2026-02-05 20:16:23.149 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.35s
2026-02-05 20:16:23.150 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 187.28
2026-02-05 20:16:23.150 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:16:23.150 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 2.121728 MB
2026-02-05 20:16:23.150 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.20.self_attn.v_proj using 256 samples
2026-02-05 20:16:23.497 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.35s
2026-02-05 20:16:23.497 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 212.92
2026-02-05 20:16:23.498 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:16:23.498 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 2.121728 MB
2026-02-05 20:16:23.498 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.20.self_attn.o_proj using 256 samples
2026-02-05 20:16:23.849 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.35s
2026-02-05 20:16:23.849 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 32.42
2026-02-05 20:16:23.849 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:16:23.849 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2026-02-05 20:16:23.849 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.20.mlp.gate_proj using 256 samples
2026-02-05 20:16:24.222 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.37s
2026-02-05 20:16:24.223 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1566.98
2026-02-05 20:16:24.223 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:16:24.223 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:16:24.223 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.20.mlp.up_proj using 256 samples
2026-02-05 20:16:24.612 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.39s
2026-02-05 20:16:24.613 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1705.58
2026-02-05 20:16:24.613 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:16:24.613 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:16:24.613 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.20.mlp.down_proj using 256 samples
2026-02-05 20:16:25.349 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.74s
2026-02-05 20:16:25.350 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 40.81
2026-02-05 20:16:25.350 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.20% | total memory: 17 GB
2026-02-05 20:16:25.350 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:16:25.350 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2026-02-05 20:16:27.316 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-02-05 20:16:27.316 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.21.self_attn.q_proj using 256 samples
2026-02-05 20:16:27.675 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.36s
2026-02-05 20:16:27.676 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 803.21
2026-02-05 20:16:27.676 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:16:27.676 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2026-02-05 20:16:27.676 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.21.self_attn.k_proj using 256 samples
2026-02-05 20:16:28.025 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.35s
2026-02-05 20:16:28.026 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 214.74
2026-02-05 20:16:28.026 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:16:28.026 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 2.121728 MB
2026-02-05 20:16:28.026 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.21.self_attn.v_proj using 256 samples
2026-02-05 20:16:28.374 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.35s
2026-02-05 20:16:28.374 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 217.12
2026-02-05 20:16:28.374 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:16:28.374 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 2.121728 MB
2026-02-05 20:16:28.374 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.21.self_attn.o_proj using 256 samples
2026-02-05 20:16:28.725 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.35s
2026-02-05 20:16:28.726 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 30.06
2026-02-05 20:16:28.726 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:16:28.726 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2026-02-05 20:16:28.726 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.21.mlp.gate_proj using 256 samples
2026-02-05 20:16:29.097 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.37s
2026-02-05 20:16:29.097 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1833.95
2026-02-05 20:16:29.097 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:16:29.097 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:16:29.097 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.21.mlp.up_proj using 256 samples
2026-02-05 20:16:29.473 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.38s
2026-02-05 20:16:29.473 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 2027.00
2026-02-05 20:16:29.473 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:16:29.473 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:16:29.473 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.21.mlp.down_proj using 256 samples
2026-02-05 20:16:30.210 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.74s
2026-02-05 20:16:30.211 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 56.20
2026-02-05 20:16:30.211 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.20% | total memory: 17 GB
2026-02-05 20:16:30.211 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:16:30.211 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2026-02-05 20:16:32.184 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-02-05 20:16:32.184 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.22.self_attn.q_proj using 256 samples
2026-02-05 20:16:32.548 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.36s
2026-02-05 20:16:32.551 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 876.07
2026-02-05 20:16:32.551 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:16:32.551 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2026-02-05 20:16:32.552 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.22.self_attn.k_proj using 256 samples
2026-02-05 20:16:32.900 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.35s
2026-02-05 20:16:32.900 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 247.95
2026-02-05 20:16:32.900 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:16:32.900 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 2.121728 MB
2026-02-05 20:16:32.900 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.22.self_attn.v_proj using 256 samples
2026-02-05 20:16:33.255 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.36s
2026-02-05 20:16:33.256 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 285.84
2026-02-05 20:16:33.256 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:16:33.256 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 2.121728 MB
2026-02-05 20:16:33.256 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.22.self_attn.o_proj using 256 samples
2026-02-05 20:16:33.606 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.35s
2026-02-05 20:16:33.606 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 44.35
2026-02-05 20:16:33.606 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:16:33.606 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2026-02-05 20:16:33.607 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.22.mlp.gate_proj using 256 samples
2026-02-05 20:16:33.983 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.38s
2026-02-05 20:16:33.983 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 2442.98
2026-02-05 20:16:33.983 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:16:33.983 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:16:33.983 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.22.mlp.up_proj using 256 samples
2026-02-05 20:16:34.358 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.37s
2026-02-05 20:16:34.358 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 2418.54
2026-02-05 20:16:34.359 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:16:34.359 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:16:34.359 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.22.mlp.down_proj using 256 samples
2026-02-05 20:16:35.119 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.76s
2026-02-05 20:16:35.120 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 83.10
2026-02-05 20:16:35.120 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.20% | total memory: 17 GB
2026-02-05 20:16:35.120 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:16:35.120 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2026-02-05 20:16:37.096 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-02-05 20:16:37.096 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.23.self_attn.q_proj using 256 samples
2026-02-05 20:16:37.457 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.36s
2026-02-05 20:16:37.458 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 974.87
2026-02-05 20:16:37.458 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:16:37.458 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2026-02-05 20:16:37.458 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.23.self_attn.k_proj using 256 samples
2026-02-05 20:16:37.805 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.35s
2026-02-05 20:16:37.806 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 287.25
2026-02-05 20:16:37.806 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:16:37.806 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 2.121728 MB
2026-02-05 20:16:37.806 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.23.self_attn.v_proj using 256 samples
2026-02-05 20:16:38.153 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.35s
2026-02-05 20:16:38.154 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 369.68
2026-02-05 20:16:38.154 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:16:38.154 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 2.121728 MB
2026-02-05 20:16:38.154 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.23.self_attn.o_proj using 256 samples
2026-02-05 20:16:38.508 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.35s
2026-02-05 20:16:38.509 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 77.10
2026-02-05 20:16:38.509 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:16:38.509 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2026-02-05 20:16:38.509 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.23.mlp.gate_proj using 256 samples
2026-02-05 20:16:38.881 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.37s
2026-02-05 20:16:38.881 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 2751.67
2026-02-05 20:16:38.882 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:16:38.882 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:16:38.882 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.23.mlp.up_proj using 256 samples
2026-02-05 20:16:39.252 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.37s
2026-02-05 20:16:39.252 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 2917.85
2026-02-05 20:16:39.252 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:16:39.252 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:16:39.253 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.23.mlp.down_proj using 256 samples
2026-02-05 20:16:39.986 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.73s
2026-02-05 20:16:39.987 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 146.59
2026-02-05 20:16:39.987 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.20% | total memory: 17 GB
2026-02-05 20:16:39.987 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:16:39.987 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2026-02-05 20:16:41.955 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-02-05 20:16:41.955 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.24.self_attn.q_proj using 256 samples
2026-02-05 20:16:42.313 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.36s
2026-02-05 20:16:42.313 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1390.62
2026-02-05 20:16:42.313 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:16:42.313 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2026-02-05 20:16:42.313 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.24.self_attn.k_proj using 256 samples
2026-02-05 20:16:42.658 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.34s
2026-02-05 20:16:42.659 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 369.92
2026-02-05 20:16:42.659 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:16:42.659 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 2.121728 MB
2026-02-05 20:16:42.659 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.24.self_attn.v_proj using 256 samples
2026-02-05 20:16:43.005 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.35s
2026-02-05 20:16:43.005 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 447.17
2026-02-05 20:16:43.005 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:16:43.005 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 2.121728 MB
2026-02-05 20:16:43.005 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.24.self_attn.o_proj using 256 samples
2026-02-05 20:16:43.355 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.35s
2026-02-05 20:16:43.356 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 41.27
2026-02-05 20:16:43.356 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:16:43.356 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2026-02-05 20:16:43.356 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.24.mlp.gate_proj using 256 samples
2026-02-05 20:16:43.726 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.37s
2026-02-05 20:16:43.726 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 2816.54
2026-02-05 20:16:43.726 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:16:43.727 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:16:43.727 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.24.mlp.up_proj using 256 samples
2026-02-05 20:16:44.099 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.37s
2026-02-05 20:16:44.099 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 3565.63
2026-02-05 20:16:44.099 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:16:44.099 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:16:44.099 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.24.mlp.down_proj using 256 samples
2026-02-05 20:16:44.831 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.73s
2026-02-05 20:16:44.832 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 185.92
2026-02-05 20:16:44.832 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.20% | total memory: 17 GB
2026-02-05 20:16:44.832 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:16:44.832 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2026-02-05 20:16:46.806 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-02-05 20:16:46.806 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.25.self_attn.q_proj using 256 samples
2026-02-05 20:16:47.164 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.36s
2026-02-05 20:16:47.164 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1584.19
2026-02-05 20:16:47.164 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:16:47.164 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2026-02-05 20:16:47.164 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.25.self_attn.k_proj using 256 samples
2026-02-05 20:16:47.510 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.35s
2026-02-05 20:16:47.510 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 400.77
2026-02-05 20:16:47.510 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:16:47.510 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 2.121728 MB
2026-02-05 20:16:47.510 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.25.self_attn.v_proj using 256 samples
2026-02-05 20:16:47.854 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.34s
2026-02-05 20:16:47.854 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 639.60
2026-02-05 20:16:47.855 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:16:47.855 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 2.121728 MB
2026-02-05 20:16:47.855 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.25.self_attn.o_proj using 256 samples
2026-02-05 20:16:48.206 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.35s
2026-02-05 20:16:48.207 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 37.14
2026-02-05 20:16:48.209 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:16:48.209 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2026-02-05 20:16:48.210 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.25.mlp.gate_proj using 256 samples
2026-02-05 20:16:48.583 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.37s
2026-02-05 20:16:48.583 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 3385.39
2026-02-05 20:16:48.584 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:16:48.584 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:16:48.584 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.25.mlp.up_proj using 256 samples
2026-02-05 20:16:48.957 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.37s
2026-02-05 20:16:48.957 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 4345.57
2026-02-05 20:16:48.957 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:16:48.957 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:16:48.957 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.25.mlp.down_proj using 256 samples
2026-02-05 20:16:49.693 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.74s
2026-02-05 20:16:49.693 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 254.39
2026-02-05 20:16:49.694 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.20% | total memory: 17 GB
2026-02-05 20:16:49.694 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:16:49.694 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2026-02-05 20:16:51.667 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-02-05 20:16:51.667 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.26.self_attn.q_proj using 256 samples
2026-02-05 20:16:52.029 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.36s
2026-02-05 20:16:52.029 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1895.84
2026-02-05 20:16:52.029 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:16:52.029 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2026-02-05 20:16:52.029 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.26.self_attn.k_proj using 256 samples
2026-02-05 20:16:52.375 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.35s
2026-02-05 20:16:52.376 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 513.01
2026-02-05 20:16:52.376 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:16:52.376 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 2.121728 MB
2026-02-05 20:16:52.376 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.26.self_attn.v_proj using 256 samples
2026-02-05 20:16:52.721 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.34s
2026-02-05 20:16:52.721 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 741.72
2026-02-05 20:16:52.721 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:16:52.721 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 2.121728 MB
2026-02-05 20:16:52.721 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.26.self_attn.o_proj using 256 samples
2026-02-05 20:16:53.072 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.35s
2026-02-05 20:16:53.073 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 31.83
2026-02-05 20:16:53.073 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:16:53.073 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2026-02-05 20:16:53.073 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.26.mlp.gate_proj using 256 samples
2026-02-05 20:16:53.444 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.37s
2026-02-05 20:16:53.447 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 4171.87
2026-02-05 20:16:53.447 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:16:53.447 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:16:53.447 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.26.mlp.up_proj using 256 samples
2026-02-05 20:16:53.818 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.37s
2026-02-05 20:16:53.818 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 5362.68
2026-02-05 20:16:53.818 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:16:53.818 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:16:53.818 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.26.mlp.down_proj using 256 samples
2026-02-05 20:16:54.554 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.74s
2026-02-05 20:16:54.555 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 399.66
2026-02-05 20:16:54.555 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.20% | total memory: 17 GB
2026-02-05 20:16:54.555 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:16:54.555 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2026-02-05 20:16:56.528 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-02-05 20:16:56.528 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.27.self_attn.q_proj using 256 samples
2026-02-05 20:16:56.884 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.36s
2026-02-05 20:16:56.884 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 2859.19
2026-02-05 20:16:56.884 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:16:56.884 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2026-02-05 20:16:56.884 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.27.self_attn.k_proj using 256 samples
2026-02-05 20:16:57.234 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.35s
2026-02-05 20:16:57.234 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 736.14
2026-02-05 20:16:57.234 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:16:57.234 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 2.121728 MB
2026-02-05 20:16:57.235 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.27.self_attn.v_proj using 256 samples
2026-02-05 20:16:57.580 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.35s
2026-02-05 20:16:57.581 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1358.45
2026-02-05 20:16:57.581 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:16:57.581 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 2.121728 MB
2026-02-05 20:16:57.581 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.27.self_attn.o_proj using 256 samples
2026-02-05 20:16:57.932 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.35s
2026-02-05 20:16:57.933 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 35.12
2026-02-05 20:16:57.933 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:16:57.933 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2026-02-05 20:16:57.933 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.27.mlp.gate_proj using 256 samples
2026-02-05 20:16:58.304 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.37s
2026-02-05 20:16:58.305 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 5258.97
2026-02-05 20:16:58.305 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:16:58.305 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:16:58.305 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.27.mlp.up_proj using 256 samples
2026-02-05 20:16:58.679 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.37s
2026-02-05 20:16:58.679 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 6996.53
2026-02-05 20:16:58.679 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:16:58.679 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:16:58.679 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.27.mlp.down_proj using 256 samples
2026-02-05 20:16:59.417 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.74s
2026-02-05 20:16:59.418 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 651.74
2026-02-05 20:16:59.418 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.20% | total memory: 17 GB
2026-02-05 20:16:59.418 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:16:59.418 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2026-02-05 20:17:01.382 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-02-05 20:17:01.383 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.28.self_attn.q_proj using 256 samples
2026-02-05 20:17:01.742 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.36s
2026-02-05 20:17:01.742 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 3285.51
2026-02-05 20:17:01.742 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:17:01.742 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2026-02-05 20:17:01.742 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.28.self_attn.k_proj using 256 samples
2026-02-05 20:17:02.094 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.35s
2026-02-05 20:17:02.095 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 846.52
2026-02-05 20:17:02.095 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:17:02.095 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 2.121728 MB
2026-02-05 20:17:02.095 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.28.self_attn.v_proj using 256 samples
2026-02-05 20:17:02.440 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.35s
2026-02-05 20:17:02.441 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1724.24
2026-02-05 20:17:02.441 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:17:02.441 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 2.121728 MB
2026-02-05 20:17:02.441 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.28.self_attn.o_proj using 256 samples
2026-02-05 20:17:02.793 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.35s
2026-02-05 20:17:02.793 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 65.37
2026-02-05 20:17:02.794 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:17:02.794 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2026-02-05 20:17:02.794 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.28.mlp.gate_proj using 256 samples
2026-02-05 20:17:03.166 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.37s
2026-02-05 20:17:03.166 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 8998.94
2026-02-05 20:17:03.167 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:17:03.167 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:17:03.167 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.28.mlp.up_proj using 256 samples
2026-02-05 20:17:03.538 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.37s
2026-02-05 20:17:03.538 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 10219.37
2026-02-05 20:17:03.539 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:17:03.539 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:17:03.539 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.28.mlp.down_proj using 256 samples
2026-02-05 20:17:04.275 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.74s
2026-02-05 20:17:04.276 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 2217.12
2026-02-05 20:17:04.276 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.20% | total memory: 17 GB
2026-02-05 20:17:04.276 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:17:04.276 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2026-02-05 20:17:06.244 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-02-05 20:17:06.244 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.29.self_attn.q_proj using 256 samples
2026-02-05 20:17:06.604 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.36s
2026-02-05 20:17:06.604 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 3254.73
2026-02-05 20:17:06.604 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:17:06.604 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2026-02-05 20:17:06.604 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.29.self_attn.k_proj using 256 samples
2026-02-05 20:17:06.950 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.35s
2026-02-05 20:17:06.950 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 922.62
2026-02-05 20:17:06.950 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:17:06.951 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 2.121728 MB
2026-02-05 20:17:06.951 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.29.self_attn.v_proj using 256 samples
2026-02-05 20:17:07.301 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.35s
2026-02-05 20:17:07.301 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1398.29
2026-02-05 20:17:07.302 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:17:07.302 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 2.121728 MB
2026-02-05 20:17:07.302 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.29.self_attn.o_proj using 256 samples
2026-02-05 20:17:07.655 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.35s
2026-02-05 20:17:07.655 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 44.26
2026-02-05 20:17:07.656 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:17:07.656 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2026-02-05 20:17:07.656 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.29.mlp.gate_proj using 256 samples
2026-02-05 20:17:08.030 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.37s
2026-02-05 20:17:08.031 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 7406.17
2026-02-05 20:17:08.031 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:17:08.031 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:17:08.031 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.29.mlp.up_proj using 256 samples
2026-02-05 20:17:08.403 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.37s
2026-02-05 20:17:08.403 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 6425.91
2026-02-05 20:17:08.403 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.81% | total memory: 17 GB
2026-02-05 20:17:08.403 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:17:08.403 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.29.mlp.down_proj using 256 samples
2026-02-05 20:17:09.139 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 0.74s
2026-02-05 20:17:09.140 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 681.49
2026-02-05 20:17:09.140 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.20% | total memory: 17 GB
2026-02-05 20:17:09.140 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 16.973824 MB
2026-02-05 20:17:09.140 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2026-02-05 20:17:10.743 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2026-02-05 20:17:10.743 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2026-02-05 20:17:12.070 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.CALIBRATION_EPOCH_END
2026-02-05 20:17:12.073 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2026-02-05 20:17:12.075 | DEBUG    | llmcompressor.core.lifecycle:finalize:134 - Finalizing compression lifecycle
2026-02-05 20:17:12.075 | DEBUG    | llmcompressor.core.lifecycle:finalize:138 - Finalized modifier: config_groups=None targets=['Linear'] ignore=['embed_tokens', 'lm_head'] scheme='W4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=True started_=True ended_=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2026-02-05 20:17:12.075 | INFO     | llmcompressor.core.lifecycle:finalize:144 - Compression lifecycle finalized for 1 modifiers
2026-02-05 20:17:12.090 | WARNING  | llmcompressor.entrypoints.utils:post_process:142 - Optimized model is not saved. To save, please provide`output_dir` as input arg.Ex. `oneshot(..., output_dir=...)`
2026-02-05 20:17:12.102 | INFO     | llmcompressor.transformers.compression.compressed_tensors_utils:get_model_compressor:193 - skip_sparsity_compression_stats set to True. Skipping sparsity compression statistic calculations. No sparsity compressor will be applied.
2026-02-05 20:17:14.584 | DEBUG    | llmcompressor.transformers.utils.helpers:infer_recipe_from_model_path:105 - No recipe found in the model_path: ./base_model
